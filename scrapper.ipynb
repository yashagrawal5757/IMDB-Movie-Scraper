{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your value: Stranger things\n"
     ]
    }
   ],
   "source": [
    "input = input(\"Enter your value: \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://www.imdb.com/find?ref_=nv_sr_fn&q=' +input+ '! &s=tt')\n",
    "#+ input+ helps in finding data of a movie dynamically entered by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = requests.get('http://www.imdb.com/find?ref_=nv_sr_fn&q= Stranger Things ! &s=tt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/title/tt4574334/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "# Fetching the movie id so that the browser can be directed to that webpage. Note out of many searches we are taking the 1st search result\n",
    "table = soup.find('table',class_='findList')\n",
    "movieid = table.tr.a['href']\n",
    "movieid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielink = \"http://www.imdb.com\" + movieid\n",
    "\n",
    "moviepage = requests.get(movielink)\n",
    "\n",
    "soup2 = BeautifulSoup(moviepage.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stranger Things'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title\n",
    "uncleaned = soup2.find('div', class_ = 'title_wrapper').h1.text\n",
    "#it contains some weird text and extra &nbsp at end\n",
    "uncleaned =uncleaned.replace('\\xa0','')\n",
    "title = uncleaned.strip()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6\n"
     ]
    }
   ],
   "source": [
    "#imdb rating\n",
    "imdbcounter=1\n",
    "try:\n",
    "    imdb_rating = float(soup2.select('.ratingValue span')[0].text)\n",
    "except:\n",
    "    imdbcounter=0\n",
    "if(imdbcounter !=0):\n",
    "    print(imdb_rating)\n",
    "else:\n",
    "    print(\"imdb rating is not given on imdb page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metascore\n",
    "try:\n",
    "    metascore = float(soup2.select('.metacriticScore span')[0].text) if float(soup2.select('.metacriticScore span')[0].text) else None\n",
    "except Exception as e:\n",
    "    metascore=None\n",
    "metascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sushant Singh Rajput',\n",
       " 'Amit Sadh',\n",
       " 'Digvijay Deshmukh',\n",
       " 'Manav Kaul',\n",
       " 'Muni Jha',\n",
       " 'Amitabh Srivastava',\n",
       " 'Irfan Khan',\n",
       " 'Rajkummar Rao',\n",
       " 'Amrita Puri',\n",
       " 'Asif Basra',\n",
       " 'Ashish Kakkad',\n",
       " 'Morli Patel',\n",
       " 'Bina Shah']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting cast values\n",
    "namelist=[]\n",
    "oddnames=[]\n",
    "evennames =[]\n",
    "ttag = soup2.find_all('tr', class_= 'odd')\n",
    "for i in ttag:\n",
    "    namelist.append( i.find('td', attrs={'class': None}))\n",
    "\n",
    "for i in namelist:\n",
    "    if (i.a) is None:\n",
    "        pass\n",
    "    else:\n",
    "        oddnames.append(i.a.string.strip())\n",
    "        \n",
    "ttag = soup2.find_all('tr', class_= 'even')\n",
    "namelist=[]\n",
    "\n",
    "for i in ttag:\n",
    "    namelist.append( i.find('td', attrs={'class': None}))\n",
    "\n",
    "for i in namelist:\n",
    "    if (i.a) is None:\n",
    "        pass\n",
    "    else:\n",
    "        evennames.append(i.a.string.strip())\n",
    "\n",
    "cast = oddnames+evennames\n",
    "cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abhishek Kapoor']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directors\n",
    "directors=[]\n",
    "director_container = soup2.find('div',class_ = 'credit_summary_item')\n",
    "\n",
    "if((director_container.find('h4').string =='Director:') or (director_container.find('h4').string =='Creator:') or\n",
    "(director_container.find('h4').string =='Creators:') or (director_container.find('h4').string =='Directors:')) :\n",
    "    directors_container = director_container.find_all('a')\n",
    "    for i in directors_container:\n",
    "        directors.append(i.string)\n",
    "else:\n",
    "    pass\n",
    "    \n",
    "directors\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get value of attrs use .attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#country\n",
    "country=[]\n",
    "titledetails = soup2.find('div',id='titleDetails')\n",
    "titleheading = titledetails.find_all('a')\n",
    "for i in range(0,len(titleheading)):\n",
    "    if('country_of_origin' in titleheading[i]['href']):\n",
    "        country.append(titleheading[i].string)\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hindi']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language\n",
    "languages=[]\n",
    "titledetails2 = soup2.find('div',id='titleDetails')\n",
    "titleheading2 = titledetails2.find_all('a')\n",
    "for i in range(0,len(titleheading2)):\n",
    "    if('primary_language' in titleheading2[i]['href']):\n",
    "        languages.append(titleheading2[i].string)\n",
    "languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is a way to find according to an attribute in tag-> consider that as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27012\n"
     ]
    }
   ],
   "source": [
    "#Total number of votes\n",
    "try:\n",
    "    votes = soup2.find('span', {'itemprop':'ratingCount'}).string\n",
    "    votes = votes.replace(',',\"\")\n",
    "    votes = int(votes)\n",
    "except Exception as e:\n",
    "    votecounter=0\n",
    "if(votecounter!=0):\n",
    "    print(votes)\n",
    "else:\n",
    "    print(\"Number of votes are not given on imdb page\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next_sibling used to get text just after a tag closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 February 2013 (India)\n"
     ]
    }
   ],
   "source": [
    "# release date\n",
    "dateheading = soup2.select('.txt-block h4')\n",
    "for i in range(0,len(dateheading)):\n",
    "    if(dateheading[i].string=='Release Date:'):\n",
    "        print(dateheading[i].next_sibling.strip())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama', 'Sport']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# genres\n",
    "genres=[]\n",
    "wrapper = soup2.select_one('.title_wrapper .subtext')\n",
    "links = wrapper.find_all('a')\n",
    "for i in links:\n",
    "    if 'genres' in i['href']:\n",
    "        genres.append(i.string)\n",
    "        \n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2h'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duration-> This considers avg duration shown on imdb page for series\n",
    "wrapper = soup2.select_one('.title_wrapper .subtext')\n",
    "duration = wrapper.find('time').string.strip()\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration is 2h\n"
     ]
    }
   ],
   "source": [
    "# Type, Duration/Seasons\n",
    "durncounter=1\n",
    "wrapper = soup2.select_one('.title_wrapper .subtext')\n",
    "links = wrapper.find_all('a')\n",
    "links\n",
    "for i in range(0,len(links)):\n",
    "    if 'releaseinfo' in links[i]['href']:\n",
    "        value = links[i].string.strip()\n",
    "if value.startswith('TV '):\n",
    "    type = 'TV Series'\n",
    "    seasons = soup2.select('.seasons-and-year-nav a')[0].string\n",
    "    duration = seasons+\" seasons\"\n",
    "else:\n",
    "    type='Movie'\n",
    "    try:\n",
    "        duration = wrapper.find('time').string.strip()\n",
    "    except Exception as e:\n",
    "        durncounter=0\n",
    "    \n",
    "\n",
    "if(type == 'Movie') and durncounter!= 0:\n",
    "    print(\"The duration is\", duration)\n",
    "elif(type == 'TV Series'):\n",
    "    print(\"The number of seasons are \", duration)\n",
    "else:\n",
    "    print(\" Duration is not given on imdb page\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is a description of the storyline - \n",
      " The story goes around the three friends who start a business, also providing coaching classes and tuition. Omi asks for help with his uncle, who is also a political leader, to start this business. Govind provides tuition classes to some children and Ishaan gives cricket coaching. They come to meet a boy, Ali who is gifted with hyper-reflex. Ishaan then starts special coaching for the boy so that the country gets a new star player. But unexpected things happen suddenly and the story takes a turn.\n"
     ]
    }
   ],
   "source": [
    "# Storyline\n",
    "# Here we have links inside story for some movies. So normal .strings wont work\n",
    "story = soup2.select_one('#titleStoryLine div span').get_text().strip()\n",
    "story\n",
    "if(story!=''):\n",
    "    print(\"\\nHere is a description of the storyline - \\n\", story)\n",
    "else:\n",
    "    print(\"\\nStory description is not given on imdb page\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Movie has been given U certificate\n"
     ]
    }
   ],
   "source": [
    "# Certificate\n",
    "wrapper = soup2.select_one('.title_wrapper .subtext')\n",
    "wrapper.next_element.strip()\n",
    "if(certificate != ''):\n",
    "    print(\"\\nThe {} has been given {} certificate\".format(type,certificate))\n",
    "else:\n",
    "    print(\"Certificate details are not given on the imdb page\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBINING ALL THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title is - Stranger Things\n",
      "\n",
      "The number of seasons are  4 seasons\n",
      "\n",
      "The imdb rating of the TV Series is = 8.8\n",
      "\n",
      "The imdb rating is calculating on the basis of 748198 mumber of votes\n",
      "\n",
      "Metascore is not available in imdb site\n",
      "\n",
      "Cast is as follows ['Winona Ryder', 'Finn Wolfhard', 'Gaten Matarazzo', 'Natalia Dyer', 'Joe Keery', 'Noah Schnapp', 'Priah Ferguson', 'Maya Hawke', 'Joe Chrest', 'David Harbour', 'Millie Bobby Brown', 'Caleb McLaughlin', 'Charlie Heaton', 'Cara Buono', 'Sadie Sink', 'Dacre Montgomery', 'Brett Gelman']\n",
      "\n",
      "Directors are ['Matt Duffer', 'Ross Duffer']\n",
      "\n",
      "Production Countries- ['USA']\n",
      "\n",
      "TV Series is available in Languages- ['English', 'Russian']\n",
      "\n",
      "TV Series was released in- 15 July 2016 (India)\n",
      "\n",
      "Following are the genres of the TV Series - ['Drama', 'Fantasy', 'Horror']\n",
      "\n",
      "The TV Series has been given 15 certificate\n",
      "\n",
      "Here is a description of the storyline - \n",
      " In a small town where everyone knows everyone, a peculiar incident starts a chain of events that leads to the disappearance of a child, which begins to tear at the fabric of an otherwise peaceful community. Dark government agencies and seemingly malevolent supernatural forces converge on the town, while a few of the locals begin to understand that there's more going on than meets the eye.\n"
     ]
    }
   ],
   "source": [
    "#title of movie/show\n",
    "uncleaned = soup2.find('div', class_ = 'title_wrapper').h1.text\n",
    "#it contains some weird text and extra &nbsp at end\n",
    "uncleaned =uncleaned.replace('\\xa0','')\n",
    "title = uncleaned.strip()\n",
    "print(\"Title is - {}\".format(title))\n",
    "\n",
    "# Type, Duration/Seasons\n",
    "durncounter=1\n",
    "wrapper = soup2.select_one('.title_wrapper .subtext')\n",
    "links = wrapper.find_all('a')\n",
    "links\n",
    "for i in range(0,len(links)):\n",
    "    if 'releaseinfo' in links[i]['href']:\n",
    "        value = links[i].string.strip()\n",
    "if value.startswith('TV '):\n",
    "    type = 'TV Series'\n",
    "    seasons = soup2.select('.seasons-and-year-nav a')[0].string\n",
    "    duration = seasons+\" seasons\"\n",
    "else:\n",
    "    type='Movie'\n",
    "    try:\n",
    "        duration = wrapper.find('time').string.strip()\n",
    "    except Exception as e:\n",
    "        durncounter=0\n",
    "    \n",
    "\n",
    "if(type == 'Movie') and durncounter!= 0:\n",
    "    print(\"\\nThe duration is\", duration)\n",
    "elif(type == 'TV Series'):\n",
    "    print(\"\\nThe number of seasons are \", duration)\n",
    "else:\n",
    "    print(\"\\nDuration is not given on imdb page\")\n",
    "\n",
    "#imdb rating\n",
    "imdbcounter=1\n",
    "try:\n",
    "    imdb_rating = float(soup2.select('.ratingValue span')[0].text)\n",
    "except Exception as e:\n",
    "    imdbcounter=0\n",
    "if(imdbcounter !=0):\n",
    "    print(\"\\nThe imdb rating of the {} is = {}\".format(type,imdb_rating))\n",
    "else:\n",
    "    print(\"\\nimdb rating is not given on imdb page\")\n",
    "\n",
    "\n",
    "#Total number of votes\n",
    "votecounter=1\n",
    "try:\n",
    "    votes = soup2.find('span', {'itemprop':'ratingCount'}).string\n",
    "    votes = votes.replace(',',\"\")\n",
    "    votes = int(votes)\n",
    "except Exception as e:\n",
    "    votecounter=0\n",
    "if(votecounter!=0):\n",
    "    print(\"\\nThe imdb rating is calculating on the basis of {} mumber of votes\".format( votes))\n",
    "else:\n",
    "    print(\"\\nNumber of votes are not given on imdb page\")\n",
    "\n",
    "#metascore    \n",
    "try:\n",
    "    metascore = float(soup2.select('.metacriticScore span')[0].text) if float(soup2.select('.metacriticScore span')[0].text) else None\n",
    "    print(\"\\nMetascore - \",metascore)\n",
    "except Exception as e:\n",
    "    metascore=None\n",
    "    print(\"\\nMetascore is not available in imdb site\")\n",
    "\n",
    "# cast values\n",
    "namelist=[]\n",
    "oddnames=[]\n",
    "evennames =[]\n",
    "ttag = soup2.find_all('tr', class_= 'odd')\n",
    "for i in ttag:\n",
    "    namelist.append( i.find('td', attrs={'class': None}))\n",
    "\n",
    "for i in namelist:\n",
    "    if (i.a) is None:\n",
    "        pass\n",
    "    else:\n",
    "        oddnames.append(i.a.string.strip())\n",
    "        \n",
    "ttag = soup2.find_all('tr', class_= 'even')\n",
    "namelist=[]\n",
    "\n",
    "for i in ttag:\n",
    "    namelist.append( i.find('td', attrs={'class': None}))\n",
    "\n",
    "for i in namelist:\n",
    "    if (i.a) is None:\n",
    "        pass\n",
    "    else:\n",
    "        evennames.append(i.a.string.strip())\n",
    "\n",
    "cast = oddnames+evennames\n",
    "print(\"\\nCast is as follows\",cast)\n",
    "\n",
    "# Extracting directors\n",
    "directors=[]\n",
    "director_container = soup2.find('div',class_ = 'credit_summary_item')\n",
    "\n",
    "if((director_container.find('h4').string =='Director:') or (director_container.find('h4').string =='Creator:') or\n",
    "(director_container.find('h4').string =='Creators:') or (director_container.find('h4').string =='Directors:')) :\n",
    "    directors_container = director_container.find_all('a')\n",
    "    for i in directors_container:\n",
    "        directors.append(i.string)\n",
    "    print(\"\\nDirectors are\", directors)\n",
    "else:\n",
    "    print(\"\\nDirector information not given in imdb site\")\n",
    "\n",
    "# Country of production\n",
    "country=[]\n",
    "titledetails = soup2.find('div',id='titleDetails')\n",
    "titleheading = titledetails.find_all('a')\n",
    "for i in range(0,len(titleheading)):\n",
    "    if('country_of_origin' in titleheading[i]['href']):\n",
    "        country.append(titleheading[i].string)\n",
    "print(\"\\nProduction Countries-\", country)\n",
    "        \n",
    "# Language\n",
    "languages=[]\n",
    "titledetails2 = soup2.find('div',id='titleDetails')\n",
    "titleheading2 = titledetails2.find_all('a')\n",
    "for i in range(0,len(titleheading2)):\n",
    "    if('primary_language' in titleheading2[i]['href']):\n",
    "        languages.append(titleheading2[i].string)\n",
    "print(\"\\n{} is available in Languages- {}\".format(type, languages))\n",
    "\n",
    "# release date\n",
    "dateheading = soup2.select('.txt-block h4')\n",
    "for i in range(0,len(dateheading)):\n",
    "    if(dateheading[i].string=='Release Date:'):\n",
    "        releasedate = dateheading[i].next_sibling.strip()\n",
    "print(\"\\n{} was released in- {}\".format(type, releasedate))\n",
    "\n",
    "        \n",
    "# genres\n",
    "genres=[]\n",
    "wrapper = soup2.select_one('.title_wrapper .subtext')\n",
    "links = wrapper.find_all('a')\n",
    "for i in links:\n",
    "    if 'genres' in i['href']:\n",
    "        genres.append(i.string)\n",
    "print(\"\\nFollowing are the genres of the {} - {}\".format(type,genres))\n",
    "\n",
    "# Certificate\n",
    "wrapper = soup2.select_one('.title_wrapper .subtext')\n",
    "certificate = wrapper.next_element.strip()\n",
    "if(certificate != ''):\n",
    "    print(\"\\nThe {} has been given {} certificate\".format(type,certificate))\n",
    "else:\n",
    "    print(\"\\nCertificate details are not given on the imdb page\")\n",
    "    \n",
    "# Storyline\n",
    "# Here we have links inside story for some movies. So normal .strings wont work\n",
    "story = soup2.select_one('#titleStoryLine div span').get_text().strip()\n",
    "if(story!=''):\n",
    "    print(\"\\nHere is a description of the storyline - \\n\", story)\n",
    "else:\n",
    "    print(\"\\nStory description is not given on imdb page\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
